{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Data Generation Pipeline for Metric Learning**\n",
    "\n",
    "**Project:** FashionCLIP (The Seeker)\n",
    "**Author:** [Tu Nombre]\n",
    "**Goal:** This notebook details the first and most critical step of the project: creating a high-quality, large-scale dataset for training a metric learning model.\n",
    "\n",
    "---\n",
    "\n",
    "### **Overview**\n",
    "Standard image datasets are often unsuitable for teaching a model nuanced concepts of similarity. To fine-tune our CLIP-based model, we need to explicitly provide it with examples of what makes two images similar or different.\n",
    "\n",
    "This pipeline programmatically generates a dataset of **triplets** and **semi-positives** from a small set of source images. The structure is as follows:\n",
    "\n",
    "-   **Anchor**: A base reference image.\n",
    "-   **Positive**: A slightly modified version of the anchor (e.g., same image, different text color). It should be \"closer\" to the anchor than any other image.\n",
    "-   **Negative**: An image from a completely different base image. It should be \"far\" from the anchor.\n",
    "-   **Semi-Positive**: A significantly modified version of the anchor (e.g., same image, different text caption). It should be \"further\" than the positive but \"closer\" than the negative.\n",
    "\n",
    "This structured dataset is the key to training our model with the `TripletSemiPosMarginWithDistanceLoss`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Configuration and Setup**\n",
    "\n",
    "First, we'll import the necessary libraries and define the core configuration parameters for our data generation process. This includes setting up paths, defining constants for image manipulation (like text padding and font sizes), and specifying the number of examples to generate. This centralized configuration makes the script easy to modify and reproduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.dataprep.data_prep import (TEXT_PATH,\n",
    "                                    MIN_LENGTH_TEXTS,\n",
    "                                    MAX_LENGHT_TEXTS,\n",
    "                                    NUM_TEXTS,\n",
    "                                    DATA_PATH,\n",
    "                                    ALL_FONTS,\n",
    "                                    ALL_COLOURS,\n",
    "                                    NUM_IMAGES,\n",
    "                                    NUM_TRIPLETS_PER_EXAMPLE,\n",
    "                                    DATASET_SAVE_PATH)\n",
    "\n",
    "from src.dataprep.data_prep import generate_examples, generate_multi_triplets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>actual_caption</th>\n",
       "      <th>font</th>\n",
       "      <th>colour</th>\n",
       "      <th>semipos</th>\n",
       "      <th>position</th>\n",
       "      <th>font_given</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>lieutenant-general.\"</td>\n",
       "      <td>lieuteynant-gene ral.\"</td>\n",
       "      <td>/usr/share/fonts/smc/Meera.ttf</td>\n",
       "      <td>black</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>(1267, 444)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>with the idea of his speedy departure.</td>\n",
       "      <td>with the idea of his speedy departure.</td>\n",
       "      <td>/usr/share/fonts/smc/Meera.ttf</td>\n",
       "      <td>black</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>(1009, 359)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>\"And I also,\" said Franz.</td>\n",
       "      <td>\"And I also,\" said Franz.</td>\n",
       "      <td>/usr/share/fonts/smc/Meera.ttf</td>\n",
       "      <td>black</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>(1118, 438)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>Greeks, and hence arises the calumny.\"</td>\n",
       "      <td>Greeks, and hence arises the calumny.\"</td>\n",
       "      <td>/usr/share/fonts/smc/Meera.ttf</td>\n",
       "      <td>black</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>(1264, 451)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>grandpapa is again thinking of it.\"</td>\n",
       "      <td>grandpVpo is fagain thinking of Sit.\"</td>\n",
       "      <td>/usr/share/fonts/smc/Meera.ttf</td>\n",
       "      <td>black</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>(817, 693)</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>lieutenant-general.\"</td>\n",
       "      <td>lieutenant-general.\"</td>\n",
       "      <td>/usr/share/fonts/smc/Meera.ttf</td>\n",
       "      <td>red</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>(1304, 373)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>with the idea of his speedy departure.</td>\n",
       "      <td>with the idea of his speedy departure.</td>\n",
       "      <td>/usr/share/fonts/smc/Meera.ttf</td>\n",
       "      <td>red</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>(1263, 379)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>\"And I also,\" said Franz.</td>\n",
       "      <td>\"And  also,\" saidFranJz.</td>\n",
       "      <td>/usr/share/fonts/smc/Meera.ttf</td>\n",
       "      <td>red</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>(1116, 349)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>Greeks, and hence arises the calumny.\"</td>\n",
       "      <td>Greeks, and hence arises the calumny.\"</td>\n",
       "      <td>/usr/share/fonts/smc/Meera.ttf</td>\n",
       "      <td>red</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>(659, 473)</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>grandpapa is again thinking of it.\"</td>\n",
       "      <td>grandpapa its Oagain thining of it.\"</td>\n",
       "      <td>/usr/share/fonts/smc/Meera.ttf</td>\n",
       "      <td>red</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>(960, 642)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             file_path  \\\n",
       "0    /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "1    /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "2    /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "3    /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "4    /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "..                                                 ...   \n",
       "295  /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "296  /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "297  /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "298  /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "299  /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "\n",
       "                                    caption  \\\n",
       "0                      lieutenant-general.\"   \n",
       "1    with the idea of his speedy departure.   \n",
       "2                 \"And I also,\" said Franz.   \n",
       "3    Greeks, and hence arises the calumny.\"   \n",
       "4       grandpapa is again thinking of it.\"   \n",
       "..                                      ...   \n",
       "295                    lieutenant-general.\"   \n",
       "296  with the idea of his speedy departure.   \n",
       "297               \"And I also,\" said Franz.   \n",
       "298  Greeks, and hence arises the calumny.\"   \n",
       "299     grandpapa is again thinking of it.\"   \n",
       "\n",
       "                             actual_caption                            font  \\\n",
       "0                    lieuteynant-gene ral.\"  /usr/share/fonts/smc/Meera.ttf   \n",
       "1    with the idea of his speedy departure.  /usr/share/fonts/smc/Meera.ttf   \n",
       "2                 \"And I also,\" said Franz.  /usr/share/fonts/smc/Meera.ttf   \n",
       "3    Greeks, and hence arises the calumny.\"  /usr/share/fonts/smc/Meera.ttf   \n",
       "4     grandpVpo is fagain thinking of Sit.\"  /usr/share/fonts/smc/Meera.ttf   \n",
       "..                                      ...                             ...   \n",
       "295                    lieutenant-general.\"  /usr/share/fonts/smc/Meera.ttf   \n",
       "296  with the idea of his speedy departure.  /usr/share/fonts/smc/Meera.ttf   \n",
       "297                \"And  also,\" saidFranJz.  /usr/share/fonts/smc/Meera.ttf   \n",
       "298  Greeks, and hence arises the calumny.\"  /usr/share/fonts/smc/Meera.ttf   \n",
       "299    grandpapa its Oagain thining of it.\"  /usr/share/fonts/smc/Meera.ttf   \n",
       "\n",
       "    colour   semipos     position  font_given  \n",
       "0    black  0.100000  (1267, 444)          40  \n",
       "1    black  0.000000  (1009, 359)          40  \n",
       "2    black  0.000000  (1118, 438)          40  \n",
       "3    black  0.000000  (1264, 451)          40  \n",
       "4    black  0.114286   (817, 693)          42  \n",
       "..     ...       ...          ...         ...  \n",
       "295    red  0.000000  (1304, 373)          40  \n",
       "296    red  0.000000  (1263, 379)          40  \n",
       "297    red  0.120000  (1116, 349)          40  \n",
       "298    red  0.000000   (659, 473)          48  \n",
       "299    red  0.085714   (960, 642)          40  \n",
       "\n",
       "[300 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(TEXT_PATH) as f:\n",
    "    lines = f.readlines()\n",
    "cleaned_lines = [l.replace('/n', '').replace('\\n', '') for l in lines if (\n",
    "    l.replace('/n', '').replace('\\n', '') != '') and MIN_LENGTH_TEXTS < len(l) < MAX_LENGHT_TEXTS]\n",
    "\n",
    "all_texts = cleaned_lines\n",
    "texts_list = np.random.choice(all_texts, NUM_TEXTS)\n",
    "\n",
    "image_names_list = [f for _, _, files in os.walk(DATA_PATH) for f in files if f.endswith('.png')][:NUM_IMAGES]\n",
    "df = generate_examples(image_names_list, fonts_list=ALL_FONTS, colour_list=ALL_COLOURS, texts_list=texts_list, image_will_be_cropped=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Generating Examples and Building Triplets**\n",
    "\n",
    "With the configuration in place, we proceed to the core logic:\n",
    "\n",
    "1.  **`generate_examples`**: This function iterates through our source images and programmatically creates thousands of variations by adding text with different fonts, colors, and positions. Each unique variation is saved as a new image.\n",
    "2.  **`generate_multi_triplets`**: For each generated image (which now serves as an \"anchor\"), this function intelligently samples the entire dataset to find corresponding positive, negative, and semi-positive partners, forming the final triplets.\n",
    "\n",
    "The final output is a Pandas DataFrame which is then saved as a Hugging Face `Dataset` object for efficient loading during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>semipos</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>with the idea of his speedy departure.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>with the idea of his speedy departure.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>with the idea of his speedy departure.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>with the idea of his speedy departure.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>with the idea of his speedy departure.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>Greeks, and hence arises the calumny.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>Greeks, and hence arises the calumny.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>Greeks, and hence arises the calumny.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>Greeks, and hence arises the calumny.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>/home/fvelasco/data/research/the-seeker/data/p...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Greeks, and hence arises the calumny.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1580 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 anchor  \\\n",
       "0     /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "1     /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "2     /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "3     /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "4     /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "...                                                 ...   \n",
       "1575  /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "1576  /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "1577  /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "1578  /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "1579  /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "\n",
       "                                                    pos  \\\n",
       "0     /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "1     /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "2     /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "3     /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "4     /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "...                                                 ...   \n",
       "1575  /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "1576  /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "1577  /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "1578  /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "1579  /home/fvelasco/data/research/the-seeker/data/p...   \n",
       "\n",
       "                                                    neg   semipos  \\\n",
       "0     /home/fvelasco/data/research/the-seeker/data/p...  0.105263   \n",
       "1     /home/fvelasco/data/research/the-seeker/data/p...  0.131579   \n",
       "2     /home/fvelasco/data/research/the-seeker/data/p...  0.000000   \n",
       "3     /home/fvelasco/data/research/the-seeker/data/p...  0.000000   \n",
       "4     /home/fvelasco/data/research/the-seeker/data/p...  0.000000   \n",
       "...                                                 ...       ...   \n",
       "1575  /home/fvelasco/data/research/the-seeker/data/p...  0.078947   \n",
       "1576  /home/fvelasco/data/research/the-seeker/data/p...  0.105263   \n",
       "1577  /home/fvelasco/data/research/the-seeker/data/p...  0.105263   \n",
       "1578  /home/fvelasco/data/research/the-seeker/data/p...  0.131579   \n",
       "1579  /home/fvelasco/data/research/the-seeker/data/p...  0.000000   \n",
       "\n",
       "                                     caption  \n",
       "0     with the idea of his speedy departure.  \n",
       "1     with the idea of his speedy departure.  \n",
       "2     with the idea of his speedy departure.  \n",
       "3     with the idea of his speedy departure.  \n",
       "4     with the idea of his speedy departure.  \n",
       "...                                      ...  \n",
       "1575  Greeks, and hence arises the calumny.\"  \n",
       "1576  Greeks, and hence arises the calumny.\"  \n",
       "1577  Greeks, and hence arises the calumny.\"  \n",
       "1578  Greeks, and hence arises the calumny.\"  \n",
       "1579  Greeks, and hence arises the calumny.\"  \n",
       "\n",
       "[1580 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_triplets = []\n",
    "part_res = df.apply(generate_multi_triplets(df, NUM_TRIPLETS_PER_EXAMPLE), axis=1).to_list()\n",
    "\n",
    "res = [l for p in part_res for l in p]\n",
    "df_result = pd.DataFrame(res, columns=['anchor', 'pos', 'neg', 'anchor_is_semipos', 'semipos', 'caption', 'actual_caption'])\n",
    "df_result = df_result[df_result.anchor_is_semipos == 0]\n",
    "df_result.reset_index(drop=True, inplace=True)\n",
    "df_result.drop(['anchor_is_semipos', 'actual_caption'], axis=1, inplace=True)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_image(self, image_name, raw_folder, num_augment, place_images_randomly,\n",
    "                predefined_positions, keep_asp_ratio, padding, min_percent, max_percent, train_or_test,\n",
    "                logo_class, logo_list, processed_folder, logo_folders):\n",
    "    \"\"\"\n",
    "    Will generate an image with the logo on it and store it in disk.\n",
    "    It will also save a df row with the information\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    -image_name : str, name of the image to be considered\n",
    "    -raw_folder: str, name of the folder where the raw images are\n",
    "    -num_augment: int, amount of times the images will be generated\n",
    "    -place_images_randomly: bool, whether to place images randomly or use a predefined position\n",
    "    -predefined_positions: list of tuples (float, float, float, float): points where the logos must be placed.\n",
    "    If more than one, then this image has more than a logo\n",
    "    -keep_asp_ratio: bool, whether to keep the aspect ratio or not\n",
    "    -padding: float: will be added to the position of the logo when inserted\n",
    "    -min_percent: max_percent: maximum percentages for increasing size\n",
    "    -train_or_test: whether if it is train or test image\n",
    "    -logo_class: class (agency) of the logo for storing\n",
    "    -logo_list: list of logos to be added (could be all PEGI for instance)\n",
    "    -logo_folders : str or list, path from the root to each folder with logos to be added\n",
    "    -processed_folder: str, path to where the processed images will be added\n",
    "    -logo_folders: the folder where the raw logo images are stored\n",
    "    \"\"\"\n",
    "    im_path = str(self.root / raw_folder / image_name)\n",
    "    im_name = image_name\n",
    "    im = Image.open(im_path)\n",
    "\n",
    "    for logo_name in logo_list:\n",
    "        logo_path = str(self.root / logo_folders / logo_name)\n",
    "        logo = Image.open(logo_path).convert(\"RGBA\")  # logo image\n",
    "        # will not resize image if it is a corner case\n",
    "        if not (logo_folders in IMAGE_GENERATION_CORNER_CASE_LOGOS):\n",
    "            if logo.size[0] > IMAGE_GENERATION_MAX_LOGO_PIXELS or \\\n",
    "                    logo.size[1] > IMAGE_GENERATION_MAX_LOGO_PIXELS:\n",
    "                logo = self.resize_logo_x_y(logo,\n",
    "                                            IMAGE_GENERATION_MAX_LOGO_PIXELS / logo.size[0],\n",
    "                                            IMAGE_GENERATION_MAX_LOGO_PIXELS / logo.size[0])\n",
    "\n",
    "        if len(logo_name.split('.')[0].split('-')) > 1:\n",
    "            # swap order country-logoname to logoname-country\n",
    "            country = logo_name.split('.')[0].split('-')[0]\n",
    "            l_name = logo_name.split('.')[0].split('-')[1] + '-' + country\n",
    "        else:\n",
    "            l_name = logo_name.split('.')[0]  # remove extension only\n",
    "        for j in range(num_augment):\n",
    "            # Logo distortion\n",
    "            if place_images_randomly:\n",
    "                if keep_asp_ratio:\n",
    "                    percentage_x = np.random.uniform(low=min_percent, high=max_percent)\n",
    "                    percentage_y = percentage_x\n",
    "                else:\n",
    "                    percentage_x = np.random.uniform(low=min_percent, high=max_percent)\n",
    "                    percentage_y = np.random.uniform(low=min_percent, high=max_percent)\n",
    "\n",
    "                if (padding < int(im.width - (padding + percentage_x * logo.width))) and (\n",
    "                        padding < int(im.height - (padding + percentage_y * logo.height))):\n",
    "                    x = np.random.randint(0 + padding,\n",
    "                                            int(im.width - (padding + percentage_x * logo.width)))\n",
    "                    y = np.random.randint(0 + padding,\n",
    "                                            int(im.height - (padding + percentage_y * logo.height)))\n",
    "                else:\n",
    "                    break\n",
    "                new_path = str(self.root / processed_folder / train_or_test / str(\n",
    "                    l_name + '_' + logo_class + '_' + str(j) + '_' + im_name))\n",
    "\n",
    "                self.include_and_save_image(new_path, x, y, percentage_x, percentage_y, logo_class, im, logo)\n",
    "\n",
    "            else:\n",
    "                # there can be more than a logo iff there are text boxes and/or in_game_purchases\n",
    "                # please note then, the order will be logo, purchases, text boxes.\n",
    "                # in case there is no purchases, an empty tuple must be included\n",
    "                for i, position in enumerate(predefined_positions):\n",
    "                    logo_classes = [logo_class, 'in_game_purchases', 'text_boxes']\n",
    "                    logo_names = [logo_name, 'in_game_purchases.png', 'text_box_1.jpg']\n",
    "                    folders = [logo_folders, 'in_game_purchases', 'text_boxes']\n",
    "                    # Will only save the image with the actual logo\n",
    "                    save_image = i < 1\n",
    "                    if not position:\n",
    "                        continue\n",
    "                    else:\n",
    "                        logo_path = str(self.root / folders[i] / logo_names[i])\n",
    "                        # In case there is more than one logo in the image, all will be included\n",
    "                        # in the df, but a single image will be saved\n",
    "                        logo_df_class = logo_classes[i]\n",
    "                        logo = Image.open(logo_path).convert(\"RGBA\")  # logo image\n",
    "                        x, y, x_max, y_max = position\n",
    "                        percentage_x = (x_max - x) / logo.width\n",
    "                        percentage_y = (y_max - y) / logo.height\n",
    "\n",
    "                        new_path = str(self.root / processed_folder / train_or_test / str(\n",
    "                            l_name + '_' + logo_class + '_' + str(j) + '_' + im_name))\n",
    "\n",
    "                        self.include_and_save_image(new_path, x, y, percentage_x, percentage_y,\n",
    "                                                    logo_df_class, im, logo,\n",
    "                                                    save_image=save_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Conclusion**\n",
    "\n",
    "The script has successfully generated and saved our structured dataset. We now have a file containing paths to thousands of anchor, positive, negative, and semi-positive images, ready to be fed into our training pipeline.\n",
    "\n",
    "**Next Step:** Use this dataset in `03_triplet_training_new_metric.ipynb` to fine-tune the `ImageEncoderNetwork`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "theSeeker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
